[["index.html", "A Minimal Book Example Chapter 1 Prerequisites", " A Minimal Book Example Yihui Xie 2024-08-08 Chapter 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],["mapping-the-risk-environment-with-oepsdata.html", "Chapter 2 Mapping the risk environment with oepsData", " Chapter 2 Mapping the risk environment with oepsData oepsData is a package created to help interact more easily with the opioid risk environment data within OEPS. The main package offerings come in the form of two functions: load_oeps_dictionary, which loads a basic data dictionary; and load_oeps, which loads OEPS data. To get a better sense of how this package can be used, let’s walk through a quick and dirty spatial investigation of poverty and working age population in Chicago. devtools::install_github(&#39;https://github.com/healthyregions/oepsData&#39;) library(oepsData) Let’s start by previewing OEPS, and seeing what data is available. As alluded above, we do this through load_oeps_dictionary. The function itself takes one required argument, scale, which is just the spatial scale we’re interested in observing. While state, county, ZCTA, and tract level data are all available, only tract level is relevant for our analysis. # See what data is available data_dictionary &lt;- load_oeps_dictionary(scale=&#39;tract&#39;) # if working in RStudio, we recommend: # View(data_dictionary) data_dictionary Based on the data dictionary, we can see that we have two variables of interest – Age18_64 and PovP. Both variables are available at multiple time periods, and they belong to different themes – social and economic, respectively. Let’s pull the data using load_oeps. We’re technically only required to provide scale and year, but we provide additional information so that we only grab the data we need. Notably, in this example we’re referring to states and counties by their FIPS codes. Illinois’ has a FIPS of 17, while Cook County has a FIPS of 031. Additionally, we’re retreiving the geometry files with this pull. # Grab the data cook_county_2010 &lt;- load_oeps( scale=&#39;tract&#39;, year=&#39;2010&#39;, themes=c(&#39;social&#39;, &#39;economic&#39;), states=&#39;17&#39;, counties=&#39;031&#39;, geometry=T) # Preview what we got head(data.frame(cook_county_2010)) library(tmap) tm_shape(cook_county_2010) + tm_fill(c(&#39;Age18_64&#39;, &#39;PovP&#39;), title = c(&#39;Working Age&#39;, &#39;Poverty\\nPercentage&#39;), style = c(&#39;sd&#39;, &#39;sd&#39;), palette = &#39;BrBG&#39;) + tm_layout(legend.position = c(&#39;left&#39;, &#39;bottom&#39;), frame=FALSE, main.title = &#39;Fewer workers correlates with higher poverty in Cook&#39;) # Grab the data chicago_metro_2010 &lt;- load_oeps( scale=&#39;tract&#39;, year=&#39;2010&#39;, theme=c(&#39;social&#39;, &#39;economic&#39;), counties=c(&#39;17031&#39;, &#39;18089&#39;), geometry=T) # Preview what we got head(data.frame(cook_county_2010)) library(tmap) tm_shape(chicago_metro_2010) + tm_fill(c(&#39;Age18_64&#39;, &#39;PovP&#39;), title = c(&#39;Working Age&#39;, &#39;Poverty\\nPercentage&#39;), style = c(&#39;sd&#39;, &#39;sd&#39;), palette = &#39;BrBG&#39;) + tm_layout(legend.position = c(&#39;left&#39;, &#39;bottom&#39;), frame=FALSE, main.title = &#39;Fewer workers correlates with higher poverty near Chi&#39;) "],["getting-oeps-data-from-bigquery.html", "Chapter 3 Getting OEPS Data from BigQuery 3.1 Setting up BigQuery 3.2 Making Queries", " Chapter 3 Getting OEPS Data from BigQuery Opioid Environment Policy Scan data is available on Google BigQuery. In this notebook, we’ll go over how to interact with the data using bigrquery. We go over two of the bigrquery APIs – one for readers familiar with SQL, and one for readers who want to avoid SQL. Lastly, readers who are already familiar with Google BigQuery will likely want to skip to Make a Query. 3.1 Setting up BigQuery When making queries against a BigQuery dataset, we do not directly query the dataset. Instead, we connect to a BigQuery profile and submit a job, which tells the profile to make the query in our stead and return the data. You can think of this like connecting to another computer to middleman the exchange. The setup allows users to work with multiple BigQuery datasets within a single profile, and also allows for billing to be separated so that data providers only pay to store the data instead of also paying for all usage of their data. To enable BigQuery, sign into a Google account on your browser of choice before navigating to this link, where you will be prompted to “Enable BigQuery.” Do so to enable your account to access BigQuery and data through BigQuery. Once BigQuery is enabled, you’ll be taken to the BigQuery studio page. This page is a hub for BigQuery interaction on the cloud, and technically also a place from which you can test out SQL queries and manage connections to external databases. In the BigQuery diagram, it’s the computer on the cloud that you submit jobs to. For our purposes, we’re interested in the resources under the explorer. By default, Google creates a default resource by mashing together random words and numbers. You can proceed using this resource, or create a new, more memorably named resource through the “+ ADD” button at the top of the Explorer pane. Whichever route you take, we need to store the name of your BigQuery project in a variable for use. As it’s the project that gets billed for the queries, it’s conventional to refer to this project as “billing.” billing &lt;- &quot;oeps-tutorial&quot; # replace this with your project name! Lastly, we need to establish that we actually have permission to create jobs on the account we created. To do that, we can use bigrquery::bq_auth(), and then grant the Tidyverse API a few permissions on our Google Account. Note that this command will prompt you to open a new window in your browser. # Opens your browser to authenticate your account bigrquery::bq_auth() 3.2 Making Queries Now that we’ve enabled BigQuery on our account, we can use it to query the OEPS data on BigQuery. First, lets back up and look at the OEPS project at a broader level. Currently, the OEPS data warehouse on BigQuery is named oeps-391119, and is divided into two datasets: tabular and spatial. The tabular dataset consists of 16 tables of attribute data at the state, county, tract, and ZCTA scales from 1980 to 2020. The spatial dataset contains the 2010 TIGER/Line geometries for each of these scales. The primary key for the datasets are HEROP_ID. A full dataset schema can be found on the OEPS BigQuery reference linked here. bigrquery offers three interfaces for interacting with BigQuery, but we introduce two here: the low-level API that uses SQL, and a higher level method using dplyr. 3.2.1 The low-level API The low-level API offers a series of methods that can be used to interact with BigQuery’s REST API. While bigrquery offers quite a few commands, it’s usually sufficient to use two: bq_project_query and bq_table_download. Using these commands, we can create and submit SQL queries to pull data tables from the OEPS data warehouse: library(bigrquery) # Our query sql &lt;- &#39;SELECT HEROP_ID, TotPop, PovP FROM oeps-391119.tabular.C_1990&#39; # Submit a job to grab the data tb &lt;- bq_project_query(billing, query=sql) # Download the results of that query to our system results &lt;- bq_table_download(tb) head(results) We can also use more complex queries: sql &lt;- &#39; SELECT C_1990.HEROP_ID, (C_2000.PovP - C_1990.PovP) AS ChangeInPovP, (C_2000.TotPop - C_1990.TotPop) AS ChangeInPop FROM oeps-391119.tabular.C_1990 INNER JOIN oeps-391119.tabular.C_2000 ON C_1990.HEROP_ID=C_2000.HEROP_ID &#39; tb &lt;- bq_project_query(billing, sql) results &lt;- bq_table_download(tb) head(results) If we want to plot this data, we need to query the spatial database. This is doable, but R interactive environments are not always a fan of the result, so we’re forced to turn results into an sf object before attempting to preview it. That is, for the following setup: library(sf) sql &lt;- &#39;SELECT HEROP_ID, geom FROM oeps-391119.spatial.counties2010&#39; tb &lt;- bq_project_query(billing, sql) this breaks: # bad results &lt;- bq_table_download(tb) head(results) And this works: # This works results &lt;- bq_table_download(tb) |&gt; st_as_sf(wkt=&#39;geom&#39;, crs=&#39;EPSG:4326&#39;) # convert geom to sf head(results) 3.2.1.1 A full low-level pipeline: Putting this all together, we can create a quick map of how county level poverty changed from 1990 to 2000: library(tmap) tmap_mode(&#39;view&#39;) sql &lt;- &#39; SELECT C_1990.HEROP_ID, (C_2000.PovP - C_1990.PovP) AS ChangeInPovP, counties2010.name, counties2010.geom FROM oeps-391119.tabular.C_1990 INNER JOIN oeps-391119.tabular.C_2000 ON C_1990.HEROP_ID=C_2000.HEROP_ID INNER JOIN oeps-391119.spatial.counties2010 ON C_1990.HEROP_ID=counties2010.HEROP_ID &#39; tb &lt;- bq_project_query(billing, sql) results &lt;- bq_table_download(tb) |&gt; st_as_sf(wkt=&#39;geom&#39;, crs=&#39;EPSG:4326&#39;) tm_shape(results) + tm_fill(&#39;ChangeInPovP&#39;, style=&#39;sd&#39;, midpoint=0, title=&#39;Change in Poverty\\n 1990 to 2000&#39;, palette=&#39;-RdYlBu&#39;) 3.2.2 The dplyr API For users with less SQL familiarity, it’s also possible to use dplyr to interact with BigQuery. We’ll need the help of DBI, a library for interacting with databases in R. # install.packages(DBI) # uncomment if needed library(dplyr) library(DBI) library(bigrquery) For this pipeline, we use DBI to connect to a given dataset (e.g. tabular), before picking a table within the dataset to interact with and then manipulate that table using dplyr. # Connect to the tabular dataset conn &lt;- dbConnect( bigquery(), project = &#39;oeps-391119&#39;, dataset = &#39;tabular&#39;, billing = billing ) # List off available tables dbListTables(conn) We can then pick a table from the above and interact with it using dplyr. C_1990 &lt;- tbl(conn, &#39;C_1990&#39;) C_1990 |&gt; select(HEROP_ID, TotPop, PovP) |&gt; collect() |&gt; head() As with the low-level API, we can also do more complex tasks, albeit with a few more lines of code: C_1990 &lt;- tbl(conn, &#39;C_1990&#39;) |&gt; select(HEROP_ID, PovP1990=PovP, TotPop1990=TotPop) |&gt; collect() C_2000 &lt;- tbl(conn, &#39;C_2000&#39;) |&gt; select(HEROP_ID, PovP2000=PovP, TotPop2000=TotPop) |&gt; collect() changes &lt;- merge(C_2000, C_1990, on=&#39;HEROP_ID&#39;) |&gt; mutate(ChangeInPovP = PovP2000-PovP1990, ChangeInTotPop = TotPop2000-TotPop1990) |&gt; select(HEROP_ID, ChangeInPovP, ChangeInTotPop) |&gt; collect() head(changes) We can also interact with spatial data. This also requires the same hack as above: we cannot preview our results until after converting them to an sf object, at least within interactive R environments. In other words, with this connection to the spatial dataset: # Connect to the spatial dataset spatial_conn &lt;- dbConnect( bigquery(), project = &#39;oeps-391119&#39;, dataset = &#39;spatial&#39;, billing = billing ) This breaks: # breaks counties2010 &lt;- tbl(spatial_conn, &#39;counties2010&#39;) |&gt; collect() head(counties2010) and this works: # works counties2010 &lt;- tbl(spatial_conn, &#39;counties2010&#39;) |&gt; collect() |&gt; st_as_sf(wkt=&#39;geom&#39;, crs=&#39;EPSG:4326&#39;) head(counties2010) 3.2.2.1 A full dplyr pipeline: Putting all the pieces together, we can make our poverty map with the following code: # Make database connections spat_conn &lt;- dbConnect( bigquery(), project = &#39;oeps-391119&#39;, dataset = &#39;spatial&#39;, billing = billing ) tab_conn &lt;- dbConnect( bigquery(), project = &#39;oeps-391119&#39;, dataset = &#39;tabular&#39;, billing = billing ) # Grab tables C_1990 &lt;- tbl(tab_conn, &quot;C_1990&quot;) C_2000 &lt;- tbl(tab_conn, &quot;C_2000&quot;) counties2010 &lt;- tbl(spat_conn, &quot;counties2010&quot;) # Data wrangling C_1990 &lt;- C_1990 |&gt; select(HEROP_ID, PovP1990=PovP) |&gt; collect() C_2000 &lt;- C_2000 |&gt; select(HEROP_ID, PovP2000=PovP) |&gt; collect() change_in_pov &lt;- merge(C_2000, C_1990, on=&#39;HEROP_ID&#39;) |&gt; mutate(ChangeInPovP=PovP2000-PovP1990) |&gt; select(HEROP_ID, ChangeInPovP) counties2010 &lt;- counties2010 |&gt; collect() |&gt; st_as_sf(wkt=&#39;geom&#39;, crs=&#39;EPSG:4326&#39;) change_in_pov &lt;- merge(counties2010, change_in_pov, on=&#39;HEROP_ID&#39;) tm_shape(results) + tm_fill(&#39;ChangeInPovP&#39;, style=&#39;sd&#39;, midpoint=0, title=&#39;Change in Poverty\\n1990 to 2000&#39;, palette=&#39;-RdYlBu&#39;) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
