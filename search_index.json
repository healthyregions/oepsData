[["index.html", "oepsData Package Documentation Chapter 1 Introduction", " oepsData Package Documentation Chapter 1 Introduction The Opioid Environment Policy Scan (OEPS) is an open-source data warehouse created by the Healthy Regions &amp; Policies Lab to support researchers in studying and modeling the opioid risk environment. This website is intended as a starting place for researchers interested in using the OEPS data. On this site, we have tutorials demonstrating two methods of accessing the Policy Scan’s data sets: first through an R package called oepsData, and secondly through bigrquery. We additionally provide a few example analyses using the data sets as a starting place for spatial research. To hear more on the project, check out the OEPS website. For more on the data itself, check out the in-depth data documentation or the online explorer "],["getting-started.html", "Chapter 2 Getting started", " Chapter 2 Getting started Installing oepsData is easy. Just run the following command to grab the newest release from GitHub. install.packages(&#39;devtools&#39;) ## Installing package into &#39;/Users/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## also installing the dependencies &#39;Rcpp&#39;, &#39;utf8&#39;, &#39;askpass&#39;, &#39;credentials&#39;, &#39;sys&#39;, &#39;zip&#39;, &#39;gitcreds&#39;, &#39;ini&#39;, &#39;httpuv&#39;, &#39;xtable&#39;, &#39;sourcetools&#39;, &#39;later&#39;, &#39;promises&#39;, &#39;fansi&#39;, &#39;systemfonts&#39;, &#39;textshaping&#39;, &#39;pillar&#39;, &#39;pkgconfig&#39;, &#39;diffobj&#39;, &#39;rematch2&#39;, &#39;clipr&#39;, &#39;crayon&#39;, &#39;curl&#39;, &#39;gert&#39;, &#39;gh&#39;, &#39;purrr&#39;, &#39;rprojroot&#39;, &#39;rstudioapi&#39;, &#39;whisker&#39;, &#39;shiny&#39;, &#39;callr&#39;, &#39;processx&#39;, &#39;downlit&#39;, &#39;httr2&#39;, &#39;openssl&#39;, &#39;ragg&#39;, &#39;tibble&#39;, &#39;xml2&#39;, &#39;htmlwidgets&#39;, &#39;stringr&#39;, &#39;vctrs&#39;, &#39;prettyunits&#39;, &#39;xopen&#39;, &#39;brew&#39;, &#39;commonmark&#39;, &#39;stringi&#39;, &#39;cpp11&#39;, &#39;brio&#39;, &#39;magrittr&#39;, &#39;praise&#39;, &#39;ps&#39;, &#39;waldo&#39;, &#39;usethis&#39;, &#39;desc&#39;, &#39;ellipsis&#39;, &#39;miniUI&#39;, &#39;pkgbuild&#39;, &#39;pkgdown&#39;, &#39;pkgload&#39;, &#39;profvis&#39;, &#39;rcmdcheck&#39;, &#39;remotes&#39;, &#39;roxygen2&#39;, &#39;rversions&#39;, &#39;sessioninfo&#39;, &#39;testthat&#39;, &#39;urlchecker&#39;, &#39;withr&#39; ## ## The downloaded binary packages are in ## /var/folders/hw/1f0gcr8d6kn9ms0_wn0_57qc0000gn/T//RtmplTKGdA/downloaded_packages devtools::install_github(&#39;https://github.com/healthyregions/oepsData&#39;) ## Using github PAT from envvar GITHUB_PAT. Use `gitcreds::gitcreds_set()` and unset GITHUB_PAT in .Renviron (or elsewhere) if you want to use the more secure git credential store instead. ## Downloading GitHub repo healthyregions/oepsData@HEAD ## R.methodsS3 (NA -&gt; 1.8.2 ) [CRAN] ## R.oo (NA -&gt; 1.26.0) [CRAN] ## wk (NA -&gt; 0.9.2 ) [CRAN] ## proxy (NA -&gt; 0.4-27) [CRAN] ## e1071 (NA -&gt; 1.7-14) [CRAN] ## digest (0.6.36 -&gt; 0.6.37) [CRAN] ## R.utils (NA -&gt; 2.12.3) [CRAN] ## units (NA -&gt; 0.8-5 ) [CRAN] ## s2 (NA -&gt; 1.1.7 ) [CRAN] ## DBI (NA -&gt; 1.2.3 ) [CRAN] ## classInt (NA -&gt; 0.4-10) [CRAN] ## data.table (NA -&gt; 1.15.4) [CRAN] ## R.cache (NA -&gt; 0.16.0) [CRAN] ## sf (NA -&gt; 1.0-16) [CRAN] ## Installing 14 packages: R.methodsS3, R.oo, wk, proxy, e1071, digest, R.utils, units, s2, DBI, classInt, data.table, R.cache, sf ## Installing packages into &#39;/Users/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## ## The downloaded binary packages are in ## /var/folders/hw/1f0gcr8d6kn9ms0_wn0_57qc0000gn/T//RtmplTKGdA/downloaded_packages ## ── R CMD build ───────────────────────────────────────────────────────────────── ## * checking for file ‘/private/var/folders/hw/1f0gcr8d6kn9ms0_wn0_57qc0000gn/T/RtmplTKGdA/remotes110f3eb36715/healthyregions-oepsData-3e4ba05/DESCRIPTION’ ... OK ## * preparing ‘oepsData’: ## * checking DESCRIPTION meta-information ... OK ## * checking for LF line-endings in source and make files and shell scripts ## * checking for empty or unneeded directories ## Removed empty directory ‘oepsData/vignettes’ ## * building ‘oepsData_0.0.0.9000.tar.gz’ ## Installing package into &#39;/Users/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) You can then load the package like any other R package: library(oepsData) Efforts are currently under way to list the package on CRAN. "],["basic-usage.html", "Chapter 3 Basic Usage 3.1 Cacheing", " Chapter 3 Basic Usage oepsData is centered around two functions: load_oeps_dictionary, which loads a basic data dictionary; and load_oeps, which directly loads OEPS data. We expect that most users will start by calling load_oeps_dictionary to look at what data is available at their desired analysis scale, followed by calling load_oeps to actually load the data. load_oeps_dictionary itself takes one argument – scale – that can be any of “tract”, “zcta”, “county”, or “state”. It returns the data dictionary (stored as a data.frame), so we recommend browsing it through the View command: # See what data is available at the state level data_dictionary &lt;- load_oeps_dictionary(scale=&quot;state&quot;) # if working in RStudio, we recommend: # View(data_dictionary) # as we&#39;re in a bookdown, we just preview it simply: head(data_dictionary) #&gt; Theme 1980 1990 2000 2010 Latest Longitudinal Variable #&gt; 201 Geography x x x x x x HEROP_ID #&gt; 202 Geography x x x x x x G_STATEFP #&gt; 203 Geography x x x x x x GEOID #&gt; 204 Geography x x x x x x STUSPS #&gt; 205 Social x x x x x x TotPop #&gt; 206 Social &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; x &lt;NA&gt; TotPopHh #&gt; Description #&gt; 201 A derived unique id corresponding to the relevant geographic unit. #&gt; 202 Two digit federal information processing standard code with a G appended to the front. #&gt; 203 Two digit federal information processing standard code. #&gt; 204 State postal abbreviation #&gt; 205 Estimated total population #&gt; 206 Total number of people in households #&gt; Metadata Location #&gt; 201 &lt;NA&gt; #&gt; 202 &lt;NA&gt; #&gt; 203 &lt;NA&gt; #&gt; 204 &lt;NA&gt; #&gt; 205 https://github.com/GeoDaCenter/opioid-policy-scan/blob/main/data_final/metadata/Age_2018.md #&gt; 206 https://github.com/GeoDaCenter/opioid-policy-scan/blob/main/data_final/metadata/HouseholdType.md #&gt; Source #&gt; 201 Healthy Regions &amp; Policies Lab, UIUC #&gt; 202 Tiger/Line 2018 #&gt; 203 Tiger/Line 2018 #&gt; 204 Tiger/Line 2018 #&gt; 205 ACS 2018, 5-Year; 2010 Decennial Census; IPUMS NHGIS #&gt; 206 ACS 2018, 5-Year #&gt; Source Long #&gt; 201 &lt;NA&gt; #&gt; 202 Tiger/Line 2018 Shapefiles #&gt; 203 Tiger/Line 2018 Shapefiles #&gt; 204 Tiger/Line 2018 Shapefiles #&gt; 205 American Community Survey 2014-2018 5 Year Estimates; 2010 Decennial Census; Integrated Public Use Microdata Service National Historic Geographic Information Systems #&gt; 206 American Community Survey 2014-2018 5 Year Estimates #&gt; OEPSv1 Type Example Data Limitations #&gt; 201 &lt;NA&gt; String 040US01-2018 &lt;NA&gt; #&gt; 202 &lt;NA&gt; String G53 &lt;NA&gt; #&gt; 203 &lt;NA&gt; String 53 &lt;NA&gt; #&gt; 204 &lt;NA&gt; String WA &lt;NA&gt; #&gt; 205 DS01 Integer 7294336 &lt;NA&gt; #&gt; 206 DS05 Integer 7151776 &lt;NA&gt; #&gt; Comments #&gt; 201 The HEROP_ID is generated as follows: Summary Level Code + &quot;US&quot; + GEOID + “-” + Year. In the case of State geographies, Summary Level Code is 040 and GEOID is State FP . #&gt; 202 &lt;NA&gt; #&gt; 203 &lt;NA&gt; #&gt; 204 &lt;NA&gt; #&gt; 205 1980, 1990, and 2000 data from respective decennial censuses downloaded from IPUMS NHGIS and aggregated upwards. #&gt; 206 &lt;NA&gt; #&gt; Analysis #&gt; 201 &lt;NA&gt; #&gt; 202 &lt;NA&gt; #&gt; 203 &lt;NA&gt; #&gt; 204 &lt;NA&gt; #&gt; 205 &lt;NA&gt; #&gt; 206 &lt;NA&gt; We might find that we’re interested in the 1990 state data. We can load that data and its geometries using load_oeps. states_1990 &lt;- load_oeps(scale=&quot;state&quot;, year=1990, geometry=TRUE) head(data.frame(states_1990)) #&gt; HEROP_ID GEOID TotPop TotUnits Age18_64 Age0_4 Age5_14 Age15_19 Age20_24 #&gt; 1 040US01 1 4040587 1670379 2458810 283295 593000 320426 305402 #&gt; 2 040US02 2 550043 232459 355331 54896 94915 37150 41228 #&gt; 3 040US04 4 3665228 1659430 2205335 292859 540097 260922 279921 #&gt; 4 040US05 5 2350725 1000667 1379536 164667 351148 179622 162750 #&gt; 5 040US06 6 29746266 11182882 18865070 2396639 4199308 2052161 2509677 #&gt; 6 040US08 8 3294394 1477348 2103684 252892 480486 224962 238451 #&gt; Age15_44 Age45_49 Age50_54 Age55_59 Age60_64 AgeOv65 Age15_24P Und45P Ovr65P #&gt; 1 1857895 224862 194559 183677 180310 522989 15.49 67.67 12.94 #&gt; 2 294441 32117 21812 16595 12897 22368 14.25 80.77 4.07 #&gt; 3 1704450 192571 156945 146658 152874 478774 14.76 69.23 13.06 #&gt; 4 1028120 132085 111252 105811 107584 350058 14.56 65.68 14.89 #&gt; 5 14882822 1619757 1281437 1133380 1098810 3134112 15.34 72.21 10.54 #&gt; 6 1643348 190203 146468 130194 121361 329442 14.07 72.14 10.00 #&gt; WhiteP BlackP HispP AmIndP AsianP PacIsP OtherP NoHsP ChildrenP PovP UnempP #&gt; 1 73.65 25.26 0.61 0.41 0.52 0.02 0.14 33.14 26.20 18.34 6.88 #&gt; 2 75.54 4.08 3.24 15.58 3.24 0.35 1.21 13.37 31.33 9.00 8.78 #&gt; 3 80.84 3.02 18.78 5.55 1.41 0.09 9.08 21.34 26.77 15.75 7.17 #&gt; 4 82.73 15.91 0.85 0.54 0.52 0.02 0.29 33.65 26.42 19.07 6.76 #&gt; 5 68.96 7.42 25.83 0.81 9.19 0.37 13.23 23.81 26.04 12.51 6.65 #&gt; 6 88.19 4.04 12.88 0.84 1.73 0.08 5.10 15.57 26.14 11.68 5.74 #&gt; VacantP geometry #&gt; 1 9.79 MULTIPOLYGON (((-85.00237 3... #&gt; 2 18.81 MULTIPOLYGON (((-164.9762 5... #&gt; 3 17.51 MULTIPOLYGON (((-109.0452 3... #&gt; 4 10.94 MULTIPOLYGON (((-94.55929 3... #&gt; 5 7.17 MULTIPOLYGON (((-122.4463 3... #&gt; 6 13.19 MULTIPOLYGON (((-102.0422 3... Which lets us operate on the data as we desire. For instance, we can make a simple map: library(tmap) #&gt; Breaking News: tmap 3.x is retiring. Please test v4, e.g. with #&gt; remotes::install_github(&#39;r-tmap/tmap&#39;) library(sf) #&gt; Linking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE # reproject to a better display CRS states_1990 &lt;- st_transform(states_1990, &quot;ESRI:102004&quot;) tm_shape(states_1990) + tm_fill(&quot;NoHsP&quot;, style=&quot;jenks&quot;) + tm_borders(alpha=0.05) + tm_layout(main.title = &quot;Population over 25 without a high school degree&quot;) 3.1 Cacheing oepsData pulls its data from online repositories, primarily GitHub. This can lead to issues for users operating on slow internet, for whom load times can be long for larger datasets, or for users who anticipate needing the package when entirely offline. To help minimize these issues, oepsData caches, or saves a local copy of, data loaded by load_oeps on its first load. Additionally, oepsData offers a few commands can help maintain caches: * cache_geometries and cache_oeps_tables cache all tables and geometries, overwriting prior ones in the process. * clear_cache deletes all cached data. * cache_dir returns the directory of the oepsData cache. Users who want to avoid using cached data and instead download data fresh every time can set cache=FALSE when calling load_oeps. "],["example-uses.html", "Chapter 4 Example uses 4.1 Data subsetting 4.2 Longitudinal analysis", " Chapter 4 Example uses 4.1 Data subsetting load_data offers a few tools to help subset data on first load. To get a better sense of how these tools can be put towards practical use, let’s walk through a quick and dirty spatial investigation of poverty and working age population in Chicago. We start by loading the data dictionary to see what data is available and into what themes they are categorized. This lets us request a subset of the full data set, which minimizes the amount of data in our environment at a time. # See what data is available data_dictionary &lt;- load_oeps_dictionary(scale=&#39;tract&#39;) # if working in RStudio, we recommend: # View(data_dictionary) head(data_dictionary) #&gt; Theme 1980 1990 2000 2010 Latest Longitudinal Variable #&gt; 432 Geography x x x x x x HEROP_ID #&gt; 433 Geography x x x x x x GEOID #&gt; 434 Geography x x x x x x TRACTCE #&gt; 435 Geography &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; x x ZIP #&gt; 436 Geography x x x x x x COUNTYFP #&gt; 437 Geography x x x x x x STATEFP #&gt; Description #&gt; 432 A derived unique id corresponding to the relevant geographic unit. #&gt; 433 Eleven digit unique geographic identifier consisting of the STATEFP, COUNTYFP, and TRACTCE. #&gt; 434 Six digit geographic key that identifies tracts. #&gt; 435 Predominant zip code. #&gt; 436 Three digit geographic key that identifies counties within a given state. #&gt; 437 Two digit geographic key that uniquely identifies states and territories. #&gt; Metadata Location Source #&gt; 432 &lt;NA&gt; Healthy Regions &amp; Policies Lab, UIUC #&gt; 433 &lt;NA&gt; Tiger/Line 2018; Tiger/Line 2010 #&gt; 434 &lt;NA&gt; Tiger/Line 2018; Tiger/Line 2010 #&gt; 435 &lt;NA&gt; HUD&#39;s PD&amp;R #&gt; 436 &lt;NA&gt; Tiger/Line 2018; Tiger/Line 2010 #&gt; 437 &lt;NA&gt; Tiger/Line 2018; Tiger/Line 2010 #&gt; Source Long #&gt; 432 &lt;NA&gt; #&gt; 433 Tiger/Line 2018 Shapefiles; Tiger/Line 2010 Shapefiles #&gt; 434 Tiger/Line 2018 Shapefiles; Tiger/Line 2010 Shapefiles #&gt; 435 Housing and Urban Development Office of Policy and Development and Research #&gt; 436 Tiger/Line 2018 Shapefiles; Tiger/Line 2010 Shapefiles #&gt; 437 Tiger/Line 2018 Shapefiles; Tiger/Line 2010 Shapefiles #&gt; OEPSv1 Type Example #&gt; 432 &lt;NA&gt; String 140US01001020100-2018 #&gt; 433 &lt;NA&gt; String 01003010705 #&gt; 434 &lt;NA&gt; String 010705 #&gt; 435 &lt;NA&gt; String 36526 #&gt; 436 &lt;NA&gt; String 003 #&gt; 437 &lt;NA&gt; String 01 #&gt; Data Limitations #&gt; 432 &lt;NA&gt; #&gt; 433 &lt;NA&gt; #&gt; 434 &lt;NA&gt; #&gt; 435 Census tracts align poorly with zips, so merging in zip data in this way will likely be very lossy. #&gt; 436 &lt;NA&gt; #&gt; 437 &lt;NA&gt; #&gt; Comments #&gt; 432 The HEROP_ID is generated as follows: Summary Level Code + &quot;US&quot; + GEOID + “-” + Year. In the case of Census Tract geographies, Summary Level Code is 140 and GEOID is State FP + County FP + Tract CE. #&gt; 433 &lt;NA&gt; #&gt; 434 &lt;NA&gt; #&gt; 435 &lt;NA&gt; #&gt; 436 &lt;NA&gt; #&gt; 437 &lt;NA&gt; #&gt; Analysis #&gt; 432 &lt;NA&gt; #&gt; 433 &lt;NA&gt; #&gt; 434 &lt;NA&gt; #&gt; 435 &lt;NA&gt; #&gt; 436 &lt;NA&gt; #&gt; 437 &lt;NA&gt; Based on the data dictionary, we can see that we have two variables of interest – Age18_64 and PovP. Both variables are available at multiple time periods, and they belong to different themes – social and economic, respectively. Let’s pull our data using load_oeps. Note how many parameters we provide information for. Geographically, we provide the FIPS code for our desired states (just Illinois) and counties (just Cook), which dramatically cuts down the number of entries retrieved. Additionally, we provide our variables of interests’ themes, lowering the number of rows retrieved. # Grab the data cook_county_2010 &lt;- load_oeps( scale=&#39;tract&#39;, year=&#39;2010&#39;, themes=c(&#39;social&#39;, &#39;economic&#39;), states=&#39;17&#39;, counties=&#39;031&#39;, geometry=T) #&gt; Warning: Some columns are type &#39;integer64&#39; but package bit64 is not installed. #&gt; Those columns will print as strange looking floating point data. There is no #&gt; need to reload the data. Simply install.packages(&#39;bit64&#39;) to obtain the #&gt; integer64 print method and print the data again. # Preview what we got head(data.frame(cook_county_2010)) #&gt; HEROP_ID GEOID TotPop TotVetPop TotUnits WhiteP BlackP AmIndP #&gt; 1 140US17031010100 8.414437e-314 4854 139 2618 37.29 50.21 0.68 #&gt; 2 140US17031010201 8.414437e-314 6450 93 3032 35.84 36.43 0.74 #&gt; 3 140US17031010202 8.414437e-314 2818 189 1271 43.90 33.82 0.64 #&gt; 4 140US17031010300 8.414437e-314 6236 141 3270 52.39 27.61 0.34 #&gt; 5 140US17031010400 8.414437e-314 5042 101 2347 66.26 14.46 0.34 #&gt; 6 140US17031010501 8.414437e-314 4091 178 2551 49.33 31.78 0.56 #&gt; AsianP PacIsP OtherP HispP Age15_24P Und45P Ovr65P Age0_4 Age5_14 Age15_19 #&gt; 1 3.09 0.02 8.71 8.67 13.04 67.02 5.71 355 542 275 #&gt; 2 4.64 0.09 22.25 20.05 13.46 72.53 4.87 563 896 396 #&gt; 3 5.07 0.04 16.54 18.31 12.63 63.48 10.97 208 290 172 #&gt; 4 5.55 0.26 13.86 13.15 10.26 59.12 14.18 360 448 237 #&gt; 5 11.15 0.10 7.70 8.51 41.63 76.10 5.22 160 200 955 #&gt; 6 9.36 0.12 8.85 10.22 13.84 69.52 9.58 223 264 138 #&gt; Age20_24 Age15_44 Age45_49 Age50_54 Age55_59 Age60_64 AgeOv65 Age18_64 DisbP #&gt; 1 358 2356 413 376 306 229 277 3519 11.2 #&gt; 2 472 3219 475 439 310 234 314 4432 9.3 #&gt; 3 184 1291 196 213 157 154 309 1886 17.1 #&gt; 4 403 2879 475 414 419 357 884 4401 9.0 #&gt; 5 1144 3477 259 280 237 166 263 4360 7.5 #&gt; 6 428 2357 289 244 178 144 392 3137 12.0 #&gt; NoHsP VetP UnempP PovP MedInc PciE GiniCoeff geometry #&gt; 1 12.61 3.73 10.07 31.95 24451 20524 0.4926 MULTIPOLYGON (((-87.66507 4... #&gt; 2 17.56 1.85 8.70 34.51 23267 20964 0.4476 MULTIPOLYGON (((-87.68281 4... #&gt; 3 16.99 8.92 12.32 26.69 18660 23806 0.4639 MULTIPOLYGON (((-87.67464 4... #&gt; 4 21.16 2.81 8.24 22.41 23303 25834 0.4632 MULTIPOLYGON (((-87.66383 4... #&gt; 5 7.66 2.40 10.75 21.00 20054 27273 0.5042 MULTIPOLYGON (((-87.66156 4... #&gt; 6 8.54 5.14 5.98 22.70 26830 26150 0.4592 MULTIPOLYGON (((-87.6613 42... We can then immediately map our data. We opt to use tmap in this example, but ggplot2 also has mapping functionality for users more familiar with the library. library(tmap) tm_shape(cook_county_2010) + tm_fill(c(&#39;Age18_64&#39;, &#39;PovP&#39;), title = c(&#39;Working Age&#39;, &#39;Poverty\\nPercentage&#39;), style = c(&#39;sd&#39;, &#39;sd&#39;), palette = &#39;BrBG&#39;) + tm_layout(legend.position = c(&#39;left&#39;, &#39;bottom&#39;), frame=FALSE, main.title = &#39;Fewer workers correlates with higher poverty in Cook&#39;) Based on the above, we observe that fewer working age individuals correlates roughly with higher poverty rates within the southern and western sides of Chicago, with this trend breaking down in northern suburbs. Chicagoland continues a little bit into northeastern Indiana; maybe the rough correlation is present there as well? To check, we can pass a list of county GEOIDS to the counties parameter of load_oeps. Note that these GEOIDS must consist of the state FIPS and county FIPS, as they would otherwise fail to uniquely identify our two counties. # Grab the data chicago_metro_2010 &lt;- load_oeps( scale=&#39;tract&#39;, year=&#39;2010&#39;, theme=c(&#39;social&#39;, &#39;economic&#39;), counties=c(&#39;17031&#39;, &#39;18089&#39;), geometry=T) # Preview what we got head(data.frame(cook_county_2010)) #&gt; HEROP_ID GEOID TotPop TotVetPop TotUnits WhiteP BlackP AmIndP #&gt; 1 140US17031010100 8.414437e-314 4854 139 2618 37.29 50.21 0.68 #&gt; 2 140US17031010201 8.414437e-314 6450 93 3032 35.84 36.43 0.74 #&gt; 3 140US17031010202 8.414437e-314 2818 189 1271 43.90 33.82 0.64 #&gt; 4 140US17031010300 8.414437e-314 6236 141 3270 52.39 27.61 0.34 #&gt; 5 140US17031010400 8.414437e-314 5042 101 2347 66.26 14.46 0.34 #&gt; 6 140US17031010501 8.414437e-314 4091 178 2551 49.33 31.78 0.56 #&gt; AsianP PacIsP OtherP HispP Age15_24P Und45P Ovr65P Age0_4 Age5_14 Age15_19 #&gt; 1 3.09 0.02 8.71 8.67 13.04 67.02 5.71 355 542 275 #&gt; 2 4.64 0.09 22.25 20.05 13.46 72.53 4.87 563 896 396 #&gt; 3 5.07 0.04 16.54 18.31 12.63 63.48 10.97 208 290 172 #&gt; 4 5.55 0.26 13.86 13.15 10.26 59.12 14.18 360 448 237 #&gt; 5 11.15 0.10 7.70 8.51 41.63 76.10 5.22 160 200 955 #&gt; 6 9.36 0.12 8.85 10.22 13.84 69.52 9.58 223 264 138 #&gt; Age20_24 Age15_44 Age45_49 Age50_54 Age55_59 Age60_64 AgeOv65 Age18_64 DisbP #&gt; 1 358 2356 413 376 306 229 277 3519 11.2 #&gt; 2 472 3219 475 439 310 234 314 4432 9.3 #&gt; 3 184 1291 196 213 157 154 309 1886 17.1 #&gt; 4 403 2879 475 414 419 357 884 4401 9.0 #&gt; 5 1144 3477 259 280 237 166 263 4360 7.5 #&gt; 6 428 2357 289 244 178 144 392 3137 12.0 #&gt; NoHsP VetP UnempP PovP MedInc PciE GiniCoeff geometry #&gt; 1 12.61 3.73 10.07 31.95 24451 20524 0.4926 MULTIPOLYGON (((-87.66507 4... #&gt; 2 17.56 1.85 8.70 34.51 23267 20964 0.4476 MULTIPOLYGON (((-87.68281 4... #&gt; 3 16.99 8.92 12.32 26.69 18660 23806 0.4639 MULTIPOLYGON (((-87.67464 4... #&gt; 4 21.16 2.81 8.24 22.41 23303 25834 0.4632 MULTIPOLYGON (((-87.66383 4... #&gt; 5 7.66 2.40 10.75 21.00 20054 27273 0.5042 MULTIPOLYGON (((-87.66156 4... #&gt; 6 8.54 5.14 5.98 22.70 26830 26150 0.4592 MULTIPOLYGON (((-87.6613 42... We can once again map the resultant data, and find that the rough correlation between lower working age population totals and higher poverty in more densely populated, coastal areas seems to hold for the broader Chicagoland area. library(tmap) tm_shape(chicago_metro_2010) + tm_fill(c(&#39;Age18_64&#39;, &#39;PovP&#39;), title = c(&#39;Working Age&#39;, &#39;Poverty\\nPercentage&#39;), style = c(&#39;sd&#39;, &#39;sd&#39;), palette = &#39;BrBG&#39;) + tm_layout(legend.position = c(&#39;left&#39;, &#39;bottom&#39;), frame=FALSE, main.title = &#39;Fewer workers correlates with higher poverty near Chi&#39;) 4.2 Longitudinal analysis "],["getting-oeps-data-from-bigquery.html", "Chapter 5 Getting OEPS Data from BigQuery 5.1 Setting up BigQuery 5.2 Making Queries", " Chapter 5 Getting OEPS Data from BigQuery Opioid Environment Policy Scan data is available on Google BigQuery. In this notebook, we’ll go over how to interact with the data using bigrquery. We go over two of the bigrquery APIs – one for readers familiar with SQL, and one for readers who want to avoid SQL. Lastly, readers who are already familiar with Google BigQuery will likely want to skip to Make a Query. 5.1 Setting up BigQuery When making queries against a BigQuery dataset, we do not directly query the dataset. Instead, we connect to a BigQuery profile and submit a job, which tells the profile to make the query in our stead and return the data. You can think of this like connecting to another computer to middleman the exchange. The setup allows users to work with multiple BigQuery datasets within a single profile, and also allows for billing to be separated so that data providers only pay to store the data instead of also paying for all usage of their data. To enable BigQuery, sign into a Google account on your browser of choice before navigating to this link, where you will be prompted to “Enable BigQuery.” Do so to enable your account to access BigQuery and data through BigQuery. Once BigQuery is enabled, you’ll be taken to the BigQuery studio page. This page is a hub for BigQuery interaction on the cloud, and technically also a place from which you can test out SQL queries and manage connections to external databases. In the BigQuery diagram, it’s the computer on the cloud that you submit jobs to. For our purposes, we’re interested in the resources under the explorer. By default, Google creates a default resource by mashing together random words and numbers. You can proceed using this resource, or create a new, more memorably named resource through the “+ ADD” button at the top of the Explorer pane. Whichever route you take, we need to store the name of your BigQuery project in a variable for use. As it’s the project that gets billed for the queries, it’s conventional to refer to this project as “billing.” billing &lt;- &quot;oeps-tutorial&quot; # replace this with your project name! Lastly, we need to establish that we actually have permission to create jobs on the account we created. To do that, we can use bigrquery::bq_auth(), and then grant the Tidyverse API a few permissions on our Google Account. Note that this command will prompt you to open a new window in your browser. # Opens your browser to authenticate your account bigrquery::bq_auth() 5.2 Making Queries Now that we’ve enabled BigQuery on our account, we can use it to query the OEPS data on BigQuery. First, lets back up and look at the OEPS project at a broader level. Currently, the OEPS data warehouse on BigQuery is named oeps-391119, and is divided into two datasets: tabular and spatial. The tabular dataset consists of 16 tables of attribute data at the state, county, tract, and ZCTA scales from 1980 to 2020. The spatial dataset contains the 2010 TIGER/Line geometries for each of these scales. The primary key for the datasets are HEROP_ID. A full dataset schema can be found on the OEPS BigQuery reference linked here. bigrquery offers three interfaces for interacting with BigQuery, but we introduce two here: the low-level API that uses SQL, and a higher level method using dplyr. 5.2.1 The low-level API The low-level API offers a series of methods that can be used to interact with BigQuery’s REST API. While bigrquery offers quite a few commands, it’s usually sufficient to use two: bq_project_query and bq_table_download. Using these commands, we can create and submit SQL queries to pull data tables from the OEPS data warehouse: library(bigrquery) # Our query sql &lt;- &#39;SELECT HEROP_ID, TotPop, PovP FROM oeps-391119.tabular.C_1990&#39; # Submit a job to grab the data tb &lt;- bq_project_query(billing, query=sql) # Download the results of that query to our system results &lt;- bq_table_download(tb) head(results) We can also use more complex queries: sql &lt;- &#39; SELECT C_1990.HEROP_ID, (C_2000.PovP - C_1990.PovP) AS ChangeInPovP, (C_2000.TotPop - C_1990.TotPop) AS ChangeInPop FROM oeps-391119.tabular.C_1990 INNER JOIN oeps-391119.tabular.C_2000 ON C_1990.HEROP_ID=C_2000.HEROP_ID &#39; tb &lt;- bq_project_query(billing, sql) results &lt;- bq_table_download(tb) head(results) If we want to plot this data, we need to query the spatial database. This is doable, but R interactive environments are not always a fan of the result, so we’re forced to turn results into an sf object before attempting to preview it. That is, for the following setup: library(sf) sql &lt;- &#39;SELECT HEROP_ID, geom FROM oeps-391119.spatial.counties2010&#39; tb &lt;- bq_project_query(billing, sql) this breaks: # bad results &lt;- bq_table_download(tb) head(results) And this works: # This works results &lt;- bq_table_download(tb) |&gt; st_as_sf(wkt=&#39;geom&#39;, crs=&#39;EPSG:4326&#39;) # convert geom to sf head(results) 5.2.1.1 A full low-level pipeline: Putting this all together, we can create a quick map of how county level poverty changed from 1990 to 2000: library(tmap) tmap_mode(&#39;view&#39;) sql &lt;- &#39; SELECT C_1990.HEROP_ID, (C_2000.PovP - C_1990.PovP) AS ChangeInPovP, counties2010.name, counties2010.geom FROM oeps-391119.tabular.C_1990 INNER JOIN oeps-391119.tabular.C_2000 ON C_1990.HEROP_ID=C_2000.HEROP_ID INNER JOIN oeps-391119.spatial.counties2010 ON C_1990.HEROP_ID=counties2010.HEROP_ID &#39; tb &lt;- bq_project_query(billing, sql) results &lt;- bq_table_download(tb) |&gt; st_as_sf(wkt=&#39;geom&#39;, crs=&#39;EPSG:4326&#39;) tm_shape(results) + tm_fill(&#39;ChangeInPovP&#39;, style=&#39;sd&#39;, midpoint=0, title=&#39;Change in Poverty\\n 1990 to 2000&#39;, palette=&#39;-RdYlBu&#39;) 5.2.2 The dplyr API For users with less SQL familiarity, it’s also possible to use dplyr to interact with BigQuery. We’ll need the help of DBI, a library for interacting with databases in R. # install.packages(DBI) # uncomment if needed library(dplyr) library(DBI) library(bigrquery) For this pipeline, we use DBI to connect to a given dataset (e.g. tabular), before picking a table within the dataset to interact with and then manipulate that table using dplyr. # Connect to the tabular dataset conn &lt;- dbConnect( bigquery(), project = &#39;oeps-391119&#39;, dataset = &#39;tabular&#39;, billing = billing ) # List off available tables dbListTables(conn) We can then pick a table from the above and interact with it using dplyr. C_1990 &lt;- tbl(conn, &#39;C_1990&#39;) C_1990 |&gt; select(HEROP_ID, TotPop, PovP) |&gt; collect() |&gt; head() As with the low-level API, we can also do more complex tasks, albeit with a few more lines of code: C_1990 &lt;- tbl(conn, &#39;C_1990&#39;) |&gt; select(HEROP_ID, PovP1990=PovP, TotPop1990=TotPop) |&gt; collect() C_2000 &lt;- tbl(conn, &#39;C_2000&#39;) |&gt; select(HEROP_ID, PovP2000=PovP, TotPop2000=TotPop) |&gt; collect() changes &lt;- merge(C_2000, C_1990, on=&#39;HEROP_ID&#39;) |&gt; mutate(ChangeInPovP = PovP2000-PovP1990, ChangeInTotPop = TotPop2000-TotPop1990) |&gt; select(HEROP_ID, ChangeInPovP, ChangeInTotPop) |&gt; collect() head(changes) We can also interact with spatial data. This also requires the same hack as above: we cannot preview our results until after converting them to an sf object, at least within interactive R environments. In other words, with this connection to the spatial dataset: # Connect to the spatial dataset spatial_conn &lt;- dbConnect( bigquery(), project = &#39;oeps-391119&#39;, dataset = &#39;spatial&#39;, billing = billing ) This breaks: # breaks counties2010 &lt;- tbl(spatial_conn, &#39;counties2010&#39;) |&gt; collect() head(counties2010) and this works: # works counties2010 &lt;- tbl(spatial_conn, &#39;counties2010&#39;) |&gt; collect() |&gt; st_as_sf(wkt=&#39;geom&#39;, crs=&#39;EPSG:4326&#39;) head(counties2010) 5.2.2.1 A full dplyr pipeline: Putting all the pieces together, we can make our poverty map with the following code: # Make database connections spat_conn &lt;- dbConnect( bigquery(), project = &#39;oeps-391119&#39;, dataset = &#39;spatial&#39;, billing = billing ) tab_conn &lt;- dbConnect( bigquery(), project = &#39;oeps-391119&#39;, dataset = &#39;tabular&#39;, billing = billing ) # Grab tables C_1990 &lt;- tbl(tab_conn, &quot;C_1990&quot;) C_2000 &lt;- tbl(tab_conn, &quot;C_2000&quot;) counties2010 &lt;- tbl(spat_conn, &quot;counties2010&quot;) # Data wrangling C_1990 &lt;- C_1990 |&gt; select(HEROP_ID, PovP1990=PovP) |&gt; collect() C_2000 &lt;- C_2000 |&gt; select(HEROP_ID, PovP2000=PovP) |&gt; collect() change_in_pov &lt;- merge(C_2000, C_1990, on=&#39;HEROP_ID&#39;) |&gt; mutate(ChangeInPovP=PovP2000-PovP1990) |&gt; select(HEROP_ID, ChangeInPovP) counties2010 &lt;- counties2010 |&gt; collect() |&gt; st_as_sf(wkt=&#39;geom&#39;, crs=&#39;EPSG:4326&#39;) change_in_pov &lt;- merge(counties2010, change_in_pov, on=&#39;HEROP_ID&#39;) tm_shape(results) + tm_fill(&#39;ChangeInPovP&#39;, style=&#39;sd&#39;, midpoint=0, title=&#39;Change in Poverty\\n1990 to 2000&#39;, palette=&#39;-RdYlBu&#39;) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
